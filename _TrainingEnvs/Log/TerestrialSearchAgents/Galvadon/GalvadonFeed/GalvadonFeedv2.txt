

	Acest model este bazat pe GalvadonFeed_01 si 02. cand vine vorba de observatii , actiuni , functie de reward. 

	Diferit va fi trainer_config.yaml si probabil setup-ul de antrenare.

	GalvadonFeedv2_01: 
		
		Pentru inceput voi incerca o retea de 256 x 2 layere , direct in FAZA 2

		Agentul nu se intersecteaza cu hrana indeajuns incat sa faca o politica din asta. 

	GalvadonFeedv2_02:
		
		Vom incerca aceeasi retea cu setup-ul din FAZA 1